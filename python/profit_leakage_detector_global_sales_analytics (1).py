# -*- coding: utf-8 -*-
"""Profit_Leakage_Detector_Global_Sales_Analytics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-gZd32kSm6PprqzS7SewrPNXD-Z38X7v

**Profit Leakage Detector: Global Revenue Performance & Risk Intelligence**

 This project simulates a real-world analytics case for a Fortune 500 company struggling with hidden profitability issues across global markets.

By combining product-level margins, regional sales trends, and customer segment data, the project detects where high revenue is masking poor profitability, helping business teams make smarter, data-backed decisions.

üîç Project Goals

  1) Project Goals
 Integrate Multi-Source Sales Data: Merge product-level sales, regional profit margins, and customer contribution data into one clean, analysis-ready view ‚Äî simulating ETL pipelines in analyst roles.


  2) Detect Profitability Risk with Business Logic: Use rule-based segmentation (CASE-style) to flag risky revenue zones where strong sales hide poor margins ‚Äî mimicking financial audits and pricing diagnostics.


  3) Segment Revenue vs Margin Across Dimensions: Analyze patterns by product-region, customer tier, and industry to uncover profit illusion zones and inefficiencies.


  4) Solve Executive-Level Business Questions: Apply consulting-grade reasoning to answer real-world prompts like:

‚ÄúWhich customers are revenue leaders but margin laggards?‚Äù

‚ÄúWhich industries drag down overall profitability?‚Äù

‚ÄúWhich product-region combos leak margin despite strong sales?‚Äù

 Rank & Prioritize Risk Segments: Build league tables using margin/revenue ranks to spotlight underperformance ‚Äî just like real analysts advising business units.



  Tools & Techniques
Python (Pandas, Seaborn, Matplotlib)

Segment-wise analysis, risk flagging, and customer profiling

Profit risk classification (no ML, pure logic-based)

Consulting-style thinking baked into business logic

**Step 1: Load the Data**
"""

from google.colab import files
uploaded = files.upload()

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Nice styling for visualizations
sns.set(style="whitegrid")
# %matplotlib inline

sales_df = pd.read_csv('sales_data (1).csv')
profit_df = pd.read_csv('profit_data.csv')
customer_df = pd.read_csv('customer_segments.csv')

# Show first few rows from each dataset to verify
print(" Sales Data:")
display(sales_df.head())

print(" Profit Data:")
display(profit_df.head())

print(" Customer Segments:")
display(customer_df.head())

"""**Step 2: Clean & Prepare Keys for Merge**"""

# Strip leading/trailing spaces from merge keys in all 3 DataFrames
sales_df['product'] = sales_df['product'].str.strip()
sales_df['region'] = sales_df['region'].str.strip()

profit_df['product'] = profit_df['product'].str.strip()
profit_df['region'] = profit_df['region'].str.strip()

customer_df['customer_id'] = customer_df['customer_id'].astype(str)
sales_df['customer_id'] = sales_df['customer_id'].astype(str)

# How many unique values do we have
print(" Unique products in profit data:", profit_df['product'].nunique())
print(" Unique regions in profit data:", profit_df['region'].nunique())
print(" Unique customer IDs in sales:", sales_df['customer_id'].nunique())
print(" Unique customer IDs in customer segments:", customer_df['customer_id'].nunique())

# null values are present in each dataset
print(" Null values in sales_df keys:")
print(sales_df[['product', 'region', 'customer_id']].isnull().sum())

print(" Null values in profit_df keys:")
print(profit_df[['product', 'region']].isnull().sum())

print("Null values in customer_df:")
print(customer_df[['customer_id']].isnull().sum())

"""**Step 3: Merge DataFrames into a Full Master View**"""

# Merge sales with customer segments using customer_id
sales_customer_df = pd.merge(
    sales_df,
    customer_df,
    on='customer_id',
    how='left'
)

sales_customer_df.rename(columns={'region_x': 'region'}, inplace=True)

print(sales_customer_df.columns.tolist())

# Merge with profit_df using proper keys
master_df = pd.merge(
    sales_customer_df,
    profit_df,
    how='left',
    on=['product', 'region']
)

# View first few rows of final master DataFrame
print(" Final Merged Dataset Preview:")
display(master_df.head())

# Check if profit_margin merged correctly
print(" Null values in profit_margin:")
print(master_df['profit_margin'].isnull().sum())

# Check columns included
print(" Columns in Master DataFrame:")
print(master_df.columns.tolist())

"""**Step 4: Exploratory Data Analysis (EDA)**"""

# Step 4.1: Basic Overview ‚Äî Shape, Duplicates, Nulls
print(" Rows and Columns:", master_df.shape)

# Column types
print(" Data types:")
print(master_df.dtypes)

# Check for nulls
print(" Nulls in dataset:")
print(master_df.isnull().sum())

# Duplicates
print(" Duplicates in sale_id:")
print(master_df['sale_id'].duplicated().sum())

# Step 4.2: Profit Margin Distribution
plt.figure(figsize=(8,5))
sns.histplot(master_df['profit_margin'].dropna(), bins=30, kde=True, color='orange')
plt.title('Profit Margin Distribution')
plt.xlabel('Profit Margin (%)')
plt.ylabel('Frequency')
plt.show()

print(master_df.columns.tolist())

# Step 4.3 Total Revenue by Region
region_rev = master_df.groupby('region')['revenue_x'].sum().sort_values(ascending=False)

plt.figure(figsize=(8,5))
sns.barplot(x=region_rev.index, y=region_rev.values, palette='Set2')
plt.title('Total Revenue by Region')
plt.xlabel('Region')
plt.ylabel('Revenue')
plt.xticks(rotation=45)
plt.show()

master_df.rename(columns={'revenue_x': 'revenue'}, inplace=True)

# Step 4.4: Revenue vs Profit by Product
prod_perf = master_df.groupby('product').agg({
    'revenue': 'sum',
    'profit_margin': 'mean'
}).reset_index()

plt.figure(figsize=(10,6))
sns.scatterplot(
    x='revenue', y='profit_margin', hue='product', data=prod_perf, s=100
)
plt.title('Product Revenue vs Average Profit Margin')
plt.xlabel('Total Revenue')
plt.ylabel('Average Profit Margin')
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()

"""**Step 5: Risk Flag Generation**


"""

# Step 5.1: Create risk_flag Column

def flag_risk(margin):
    if margin < 10:
        return 'üî¥ High Risk'
    elif 10 <= margin <= 20:
        return 'üü° Moderate Risk'
    else:
        return 'üü¢ Low Risk'

# Apply logic to master DataFrame
master_df['risk_flag'] = master_df['profit_margin'].apply(flag_risk)

# Preview
master_df[['product', 'region', 'revenue', 'profit_margin', 'risk_flag']].head(10)

# Step 5.2: Visualize Risk Distribution

plt.figure(figsize=(7,5))
sns.countplot(x='risk_flag', data=master_df, palette='Set2')
plt.title('Risk Distribution')
plt.xlabel('Risk Flag')
plt.ylabel('Count')
plt.show()

""" **Step 6: Segment-Wise Deep Analysis**"""

# Step 6.1: Revenue & Average Margin by Industry

industry_perf = master_df.groupby('industry').agg({
    'revenue': 'sum',
    'profit_margin': 'mean'
}).reset_index().sort_values(by='revenue', ascending=False)

plt.figure(figsize=(10,6))
sns.barplot(x='industry', y='revenue', data=industry_perf, palette='viridis')
plt.title('Total Revenue by Industry')
plt.xticks(rotation=45)
plt.ylabel('Revenue')
plt.show()


plt.figure(figsize=(10,6))
sns.barplot(x='industry', y='profit_margin', data=industry_perf, palette='coolwarm')
plt.title('Average Profit Margin by Industry')
plt.xticks(rotation=45)
plt.ylabel('Profit Margin (%)')
plt.show()

# Step 6.2: Top Customers by Revenue + Average Margin

customer_perf = master_df.groupby('customer_name').agg({
    'revenue': 'sum',
    'profit_margin': 'mean'
}).reset_index().sort_values(by='revenue', ascending=False).head(10)

plt.figure(figsize=(10,6))
sns.barplot(x='revenue', y='customer_name', data=customer_perf, palette='crest')
plt.title('Top 10 Customers by Revenue (w/ Avg Margin)')
plt.xlabel('Total Revenue')
plt.ylabel('Customer Name')
plt.show()

# Display top customers with margin risk insight
customer_perf

# Step 6.3: Regional Comparison ‚Äì Revenue vs Margin

region_perf = master_df.groupby('region').agg({
    'revenue': 'sum',
    'profit_margin': 'mean'
}).reset_index()

plt.figure(figsize=(8,5))
sns.scatterplot(data=region_perf, x='revenue', y='profit_margin', hue='region', s=150)
plt.title('Revenue vs Profit Margin by Region')
plt.xlabel('Total Revenue')
plt.ylabel('Average Profit Margin')
plt.axhline(y=15, color='red', linestyle='--', label='Risk Margin Line (15%)')
plt.legend()
plt.show()

"""**Step 7: Ranking & Risk League Tables**"""

#Step 7.1: Rank Products by Revenue within Region
product_region_perf = master_df.groupby(['region', 'product'])['revenue'].sum().reset_index()

# Rank products within each region by revenue
product_region_perf['revenue_rank'] = product_region_perf.groupby('region')['revenue'].rank(ascending=False)


product_region_perf.sort_values(['region', 'revenue_rank']).head(10)

# Step 7.2: Rank Customers by Profit Leakage Risk
customer_risk = master_df.groupby('customer_name').agg({
    'revenue': 'sum',
    'profit_margin': 'mean'
}).reset_index()

# Filter: Only customers with avg margin < 15%
leak_risk_customers = customer_risk[customer_risk['profit_margin'] < 15]

leak_risk_customers['risk_rank'] = leak_risk_customers['revenue'].rank(ascending=False)


leak_risk_customers.sort_values('risk_rank').head(10)

# 7.3: Heatmap of Top 5 Products in Top 3 Regions
top_regions = product_region_perf['region'].value_counts().index[:3].tolist()
top_products = product_region_perf['product'].value_counts().index[:5].tolist()

heatmap_data = master_df[
    master_df['region'].isin(top_regions) & master_df['product'].isin(top_products)
]

pivot = heatmap_data.pivot_table(
    index='product',
    columns='region',
    values='revenue',
    aggfunc='sum'
)

plt.figure(figsize=(8,6))
sns.heatmap(pivot, annot=True, fmt='.0f', cmap='YlGnBu')
plt.title('Top Product Revenue Heatmap (Top 3 Regions)')
plt.show()

"""**Step 8: Business-Style Questions (Simulated Consulting Case Scenarios)**"""

# Q1: "List all product-region pairs with revenue > ‚Çπ50,000 but margin < 20%"
leak_hotspots = master_df.groupby(['product', 'region']).agg({
    'revenue': 'sum',
    'profit_margin': 'mean'
}).reset_index()

leak_hotspots = leak_hotspots[
    (leak_hotspots['revenue'] > 50000) &
    (leak_hotspots['profit_margin'] < 20)
].sort_values(by='revenue', ascending=False)

leak_hotspots.head(10)

# Q2: "Who are the top 5 customers associated with lowest average margin?
low_margin_customers = master_df.groupby('customer_name').agg({
    'revenue': 'sum',
    'profit_margin': 'mean'
}).reset_index()

low_margin_customers = low_margin_customers.sort_values(by='profit_margin').head(5)
low_margin_customers

#Q3: "Which industry earns high revenue but operates below average margin?"
# Overall avg margin
overall_avg_margin = master_df['profit_margin'].mean()

# Grouped by industry
industry_risk = master_df.groupby('industry').agg({
    'revenue': 'sum',
    'profit_margin': 'mean'
}).reset_index()

# Filter industries leaking margin
industry_risk = industry_risk[
    industry_risk['profit_margin'] < overall_avg_margin
].sort_values(by='revenue', ascending=False)

industry_risk

# Q4: "Which regions are underperforming despite contributing > ‚Çπ100,000 in revenue?"
region_perf = master_df.groupby('region').agg({
    'revenue': 'sum',
    'profit_margin': 'mean'
}).reset_index()

underperforming_regions = region_perf[
    (region_perf['revenue'] > 100000) &
    (region_perf['profit_margin'] < 15)
]

underperforming_regions

# Q5: "Which customers are over 2x average revenue contribution but under 15% profit?"
avg_contrib = master_df['revenue'].mean()

key_customers = master_df.groupby('customer_name').agg({
    'revenue': 'sum',
    'profit_margin': 'mean'
}).reset_index()

key_customers = key_customers[
    (key_customers['revenue'] > 2 * avg_contrib) &
    (key_customers['profit_margin'] < 15)
].sort_values(by='revenue', ascending=False)

key_customers.head(5)

